// Auto generated by utensor-cli

#include "frozen_model.hpp"
#include "uTensor/ops/MathOps.hpp"
#include "uTensor/core/context.hpp"
#include "uTensor/ops/ArrayOps.hpp"
#include "uTensor/ops/MatrixOps.hpp"
#include "frozen_model_weight.hpp"
#include "uTensor/core/tensor.hpp"
#include "uTensor/ops/NnOps.hpp"


void get_frozen_model_ctx(Context& ctx, Tensor* input_0) {

{ // add tensor for placeholders
    ctx.add(input_0, "deepq/input/Ob:0", 3);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_flatten_Reshape_eightbit_deepq_input_Ob__port__0_reshape_dims_0), 
            "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/input/Ob:0", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reshape_dims:0" },
             { "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_flatten_Reshape_eightbit_deepq_input_Ob__port__0_reduction_dims_0), 
            "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reshape:0", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reduction_dims:0" },
             { "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reshape:0", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/reduction_dims:0" },
             { "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/input/Ob:0",  "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/min:0", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/max:0" },
             {  "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:0",  "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:1", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/flatten/Shape:0", 1);
    ctx.push(new ShapeOp(),
             { "deepq/input/Ob:0" },
             { "deepq/model/action_value/flatten/Shape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_flatten_strided_slice_stack_0), 
            "deepq/model/action_value/flatten/strided_slice/stack:0", 
            1);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_flatten_strided_slice_stack_1_0), 
            "deepq/model/action_value/flatten/strided_slice/stack_1:0", 
            2);
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/flatten/strided_slice:0", 1);
    ctx.push(new StridedSliceOp<int>(0, 0, 0, 0, 1),
             { "deepq/model/action_value/flatten/Shape:0", "deepq/model/action_value/flatten/strided_slice/stack:0", "deepq/model/action_value/flatten/strided_slice/stack_1:0", "deepq/model/action_value/flatten/strided_slice/stack_1:0" },
             { "deepq/model/action_value/flatten/strided_slice:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_flatten_Reshape_shape_1_0), 
            "deepq/model/action_value/flatten/Reshape/shape/1:0", 
            1);
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/flatten/Reshape/shape:0", 1);
    ctx.push(new PackOp<int>(2, 0),
             { "deepq/model/action_value/flatten/strided_slice:0", "deepq/model/action_value/flatten/Reshape/shape/1:0" },
             { "deepq/model/action_value/flatten/Reshape/shape:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/flatten/Reshape/eightbit:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/flatten/Reshape/eightbit:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/flatten/Reshape/eightbit:2", 1);
    ctx.push(new QuantizedReshapeOp(),
              { "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:0", "deepq/model/action_value/flatten/Reshape/shape:0", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:1", "deepq/model/action_value/flatten/Reshape_eightbit/deepq/input/Ob__port__0/quantize:2" },
              { "deepq/model/action_value/flatten/Reshape/eightbit:0", "deepq/model/action_value/flatten/Reshape/eightbit:1", "deepq/model/action_value/flatten/Reshape/eightbit:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({6,20}, inline_deepq_model_action_value_fully_connected_weights_0), 
            "deepq/model/action_value/fully_connected/weights:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_MatMul_eightbit_deepq_model_action_value_fully_connected_weights_read__port__0_reshape_dims_0), 
            "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/model/action_value/fully_connected/weights:0", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reshape_dims:0" },
             { "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_MatMul_eightbit_deepq_model_action_value_fully_connected_weights_read__port__0_reduction_dims_0), 
            "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reshape:0", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reshape:0", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/model/action_value/fully_connected/weights:0",  "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/min:0", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/max:0" },
             {  "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:0",  "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:1", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/fully_connected/MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "deepq/model/action_value/flatten/Reshape/eightbit:0", "deepq/model/action_value/flatten/Reshape/eightbit:1", "deepq/model/action_value/flatten/Reshape/eightbit:2", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:0", "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:1",  "deepq/model/action_value/fully_connected/MatMul_eightbit/deepq/model/action_value/fully_connected/weights/read__port__0/quantize:2" },
             { "deepq/model/action_value/fully_connected/MatMul/eightbit:0", "deepq/model/action_value/fully_connected/MatMul/eightbit:1",  "deepq/model/action_value/fully_connected/MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "deepq/model/action_value/fully_connected/MatMul/eightbit:0", "deepq/model/action_value/fully_connected/MatMul/eightbit:1", "deepq/model/action_value/fully_connected/MatMul/eightbit:2" },
             { "deepq/model/action_value/fully_connected/MatMul/eightbit/requant_range:0", "deepq/model/action_value/fully_connected/MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "deepq/model/action_value/fully_connected/MatMul/eightbit:0", "deepq/model/action_value/fully_connected/MatMul/eightbit:1", "deepq/model/action_value/fully_connected/MatMul/eightbit:2", "deepq/model/action_value/fully_connected/MatMul/eightbit/requant_range:0", "deepq/model/action_value/fully_connected/MatMul/eightbit/requant_range:1" },
             { "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:0", "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:1", "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({20}, inline_deepq_model_action_value_fully_connected_biases_0), 
            "deepq/model/action_value/fully_connected/biases:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_BiasAdd_eightbit_deepq_model_action_value_fully_connected_biases_read__port__0_reshape_dims_0), 
            "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/model/action_value/fully_connected/biases:0", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reshape_dims:0" },
             { "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_BiasAdd_eightbit_deepq_model_action_value_fully_connected_biases_read__port__0_reduction_dims_0), 
            "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reshape:0", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reshape:0", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/model/action_value/fully_connected/biases:0",  "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/min:0", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/max:0" },
             {  "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:0",  "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:1", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/fully_connected/BiasAdd/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd/eightbit:2", 2);
    ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
             { "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:0", "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:1", "deepq/model/action_value/fully_connected/MatMul/eightbit/requantize:2", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:0", "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:1",  "deepq/model/action_value/fully_connected/BiasAdd_eightbit/deepq/model/action_value/fully_connected/biases/read__port__0/quantize:2" },
             { "deepq/model/action_value/fully_connected/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit:1",  "deepq/model/action_value/fully_connected/BiasAdd/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "deepq/model/action_value/fully_connected/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit:1", "deepq/model/action_value/fully_connected/BiasAdd/eightbit:2" },
             { "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requant_range:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "deepq/model/action_value/fully_connected/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit:1", "deepq/model/action_value/fully_connected/BiasAdd/eightbit:2", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requant_range:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requant_range:1" },
             { "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:1", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/Relu/eightbit:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/Relu/eightbit:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/Relu/eightbit:2", 1);
    ctx.push(new QuantizedReluOp<uint8_t, float, uint8_t>(), 
             { "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:0", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:1", "deepq/model/action_value/fully_connected/BiasAdd/eightbit/requantize:2" },
             { "deepq/model/action_value/Relu/eightbit:0", "deepq/model/action_value/Relu/eightbit:1", "deepq/model/action_value/Relu/eightbit:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({20,20}, inline_deepq_model_action_value_fully_connected_1_weights_0), 
            "deepq/model/action_value/fully_connected_1/weights:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_1_MatMul_eightbit_deepq_model_action_value_fully_connected_1_weights_read__port__0_reshape_dims_0), 
            "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/model/action_value/fully_connected_1/weights:0", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reshape_dims:0" },
             { "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_1_MatMul_eightbit_deepq_model_action_value_fully_connected_1_weights_read__port__0_reduction_dims_0), 
            "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/model/action_value/fully_connected_1/weights:0",  "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/min:0", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/max:0" },
             {  "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:0",  "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:1", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/fully_connected_1/MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "deepq/model/action_value/Relu/eightbit:0", "deepq/model/action_value/Relu/eightbit:1", "deepq/model/action_value/Relu/eightbit:2", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:0", "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:1",  "deepq/model/action_value/fully_connected_1/MatMul_eightbit/deepq/model/action_value/fully_connected_1/weights/read__port__0/quantize:2" },
             { "deepq/model/action_value/fully_connected_1/MatMul/eightbit:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit:1",  "deepq/model/action_value/fully_connected_1/MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "deepq/model/action_value/fully_connected_1/MatMul/eightbit:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit:1", "deepq/model/action_value/fully_connected_1/MatMul/eightbit:2" },
             { "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "deepq/model/action_value/fully_connected_1/MatMul/eightbit:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit:1", "deepq/model/action_value/fully_connected_1/MatMul/eightbit:2", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requant_range:1" },
             { "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:1", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({20}, inline_deepq_model_action_value_fully_connected_1_biases_0), 
            "deepq/model/action_value/fully_connected_1/biases:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_1_BiasAdd_eightbit_deepq_model_action_value_fully_connected_1_biases_read__port__0_reshape_dims_0), 
            "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/model/action_value/fully_connected_1/biases:0", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reshape_dims:0" },
             { "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_1_BiasAdd_eightbit_deepq_model_action_value_fully_connected_1_biases_read__port__0_reduction_dims_0), 
            "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/model/action_value/fully_connected_1/biases:0",  "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/min:0", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/max:0" },
             {  "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:0",  "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:1", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:2", 2);
    ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
             { "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:0", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:1", "deepq/model/action_value/fully_connected_1/MatMul/eightbit/requantize:2", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:0", "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:1",  "deepq/model/action_value/fully_connected_1/BiasAdd_eightbit/deepq/model/action_value/fully_connected_1/biases/read__port__0/quantize:2" },
             { "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:1",  "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:1", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:2" },
             { "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:1", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit:2", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requant_range:1" },
             { "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:1", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/Relu_1/eightbit:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/Relu_1/eightbit:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/Relu_1/eightbit:2", 1);
    ctx.push(new QuantizedReluOp<uint8_t, float, uint8_t>(), 
             { "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:0", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:1", "deepq/model/action_value/fully_connected_1/BiasAdd/eightbit/requantize:2" },
             { "deepq/model/action_value/Relu_1/eightbit:0", "deepq/model/action_value/Relu_1/eightbit:1", "deepq/model/action_value/Relu_1/eightbit:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({20,3}, inline_deepq_model_action_value_fully_connected_2_weights_0), 
            "deepq/model/action_value/fully_connected_2/weights:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_2_MatMul_eightbit_deepq_model_action_value_fully_connected_2_weights_read__port__0_reshape_dims_0), 
            "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/model/action_value/fully_connected_2/weights:0", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reshape_dims:0" },
             { "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_2_MatMul_eightbit_deepq_model_action_value_fully_connected_2_weights_read__port__0_reduction_dims_0), 
            "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/model/action_value/fully_connected_2/weights:0",  "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/min:0", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/max:0" },
             {  "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:0",  "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:1", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/fully_connected_2/MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "deepq/model/action_value/Relu_1/eightbit:0", "deepq/model/action_value/Relu_1/eightbit:1", "deepq/model/action_value/Relu_1/eightbit:2", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:0", "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:1",  "deepq/model/action_value/fully_connected_2/MatMul_eightbit/deepq/model/action_value/fully_connected_2/weights/read__port__0/quantize:2" },
             { "deepq/model/action_value/fully_connected_2/MatMul/eightbit:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit:1",  "deepq/model/action_value/fully_connected_2/MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "deepq/model/action_value/fully_connected_2/MatMul/eightbit:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit:1", "deepq/model/action_value/fully_connected_2/MatMul/eightbit:2" },
             { "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "deepq/model/action_value/fully_connected_2/MatMul/eightbit:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit:1", "deepq/model/action_value/fully_connected_2/MatMul/eightbit:2", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requant_range:1" },
             { "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:1", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({3}, inline_deepq_model_action_value_fully_connected_2_biases_0), 
            "deepq/model/action_value/fully_connected_2/biases:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_2_BiasAdd_eightbit_deepq_model_action_value_fully_connected_2_biases_read__port__0_reshape_dims_0), 
            "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "deepq/model/action_value/fully_connected_2/biases:0", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reshape_dims:0" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_deepq_model_action_value_fully_connected_2_BiasAdd_eightbit_deepq_model_action_value_fully_connected_2_biases_read__port__0_reduction_dims_0), 
            "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reshape:0", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/reduction_dims:0" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "deepq/model/action_value/fully_connected_2/biases:0",  "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/min:0", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/max:0" },
             {  "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:0",  "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:1", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:2", 2);
    ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
             { "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:0", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:1", "deepq/model/action_value/fully_connected_2/MatMul/eightbit/requantize:2", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:0", "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:1",  "deepq/model/action_value/fully_connected_2/BiasAdd_eightbit/deepq/model/action_value/fully_connected_2/biases/read__port__0/quantize:2" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:1",  "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:1", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:2" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:1", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit:2", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requant_range:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requant_range:1" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:1", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>(), "deepq/model/action_value/fully_connected_2/BiasAdd:0");
    ctx.push(new DequantizeOp(), 
             { "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:0", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:1", "deepq/model/action_value/fully_connected_2/BiasAdd/eightbit/requantize:2" },
             { "deepq/model/action_value/fully_connected_2/BiasAdd:0" });
}
}